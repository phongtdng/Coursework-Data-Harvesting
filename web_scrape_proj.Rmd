---
title: "Scraping data on personal health products from Mercadona and Clarel to determine price differences between male and non-male marketed products"
author: "Phong Duong, Rianne Nienke Visscher"
date: "2024-02-15"
output: html_document
editor_options: 
  chunk_output_type: inline
---

## Library

```{r}
library(xml2)
library(tidyverse)
library(RSelenium)
library(httr)
library(ROSE)
library(broom)
library(glue)
library(dplyr)
```

## Introduction

When strolling trough the isles of personal care products in a drug store or the supermarket, one would notice that products are clearly targeted at men or women. One would also notice that the majority of the isle is coloured pink, as the majority of personal care products are specifically marketed towards women. However, these pink products are also usally priced higher compared to the blue coloured, male-targeted products. This overpricing of female products is known as the 'Pink tax' and is prevalent among all sorts of products ranging from clothing to toys (Economic Committee United States Congress, 2016). Guittar et al. (2022) researched this *pink tax* of personal health products in the US and find that women tend to pay more for products such as deodorants and lotions, whereas men tend to pay more for shaving gels.

This assignment aims to investigate price differences in personal care products in Spain. More specifically, it aims to answer the question of whether male personal care products are priced differently compared to non-male products. To obtain the data needed for this analysis, data on personal health care products is extracted from the websites of Mercadona and Clarel, a large Spanish supermarket and drugstore chain respectively. Then, mean comparisons are performed to determine any price differences between male and non-male products for different types of personal health products. Unfortunately, the structure of the obtained data does not allow to investigate price differences between male and female marketed products as the identification of the gender marketed of these products is done using the product or category name which contain information on the gender when it involves a male marketed product but not when it involves a female marketed products. Future research can utilise image detection methods to indicate the gender of the products but this is out of the scope of this assignment.

This assignment is structured as follow: first the data on the personal health product from the Mercadona and the Clarel website are scraped and cleaned and added to a data frame. Then, the data is balanced after which t-test will be utilised to examine the price differences.

In addition to the analysis of the price differences, we also created a dashboard with Shiny to help consumers be more aware of the products that might be overcharged due to gender-specific marketing. The dashboard also computes annual overcharged amount of the selected products and make recommendation on which products to switch in order to avoid the overcharge. To run the Shiny App, simply open "app.R" and click on "Run App" button on the panel at the top or press "Ctrl + Shift + Enter" for Windows or "Command + Shift + Enter" for Mac.

## Mercadona

### Setting up RSelenium

First, the user agent is being set to provide the website that is being scraped with the information of the scraper. This is done to allow the webmaster to contact the scraper in case she is causing any problems for the functioning of the website. Then the background browser is being opened using the command `rsDriver()`. The URL of the supermarket Mercadona is loaded into a variable called `merc` which is then inserted into the `remDr$client$navigate()` function, to browse the Mercadona website in the background browser.

```{r}

#Set the user agent
set_config(
  user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36; Nienke Visscher / nienvis@gmail.com")
)

#Opening hidden browser
remDr <- rsDriver(port = 4468L, browser = "firefox",  verbose=F, chromever = NULL)

#Loadingf the Mercadona url into the variable 'merc'
merc <-"https://tienda.mercadona.es/categories"
 
#Browsing to the website of Mercadona in the hidden browser
remDr$client$navigate(merc)


```

### Obtaining URLs

#### Clicking through opening page

First, the function `remDr$client` is summarised into `driver`. The following chunk should only be executed when the port is newly initiated. Before one is allowed to browse the Mercadona website, the cookies need to be accepted (or rejected) and an input of postal code is required. After each `clickElement()`, a system sleep of 1 second is programmed to avoid errors coming from the code running faster than selenium server is able to browse.

```{r}

#Summarising the function'remDr$client' into 'driver'
driver <- remDr$client

Sys.sleep(3)

#Note following only when having newly initiated the port
#Accepting cookies
driver$findElement(value = "(//button[@class = 'ui-button ui-button--small ui-button--tertiary ui-button--positive'])[1]")$clickElement()

#Click on text box
driver$findElement(value = "(//input[@class = 'ym-hide-content'])[1]")$clickElement()

#Define findElement of the textbox
codigo <-driver$findElement(value = "(//input[@class = 'ym-hide-content'])[1]")

#Fill in the text box
codigo$sendKeysToElement(list("28014"))

#Click 
driver$findElement(value = "(//button[@class = 'button button-primary button-big'])[1]")$clickElement()

Sys.sleep(1)

```

#### Obtain the URLs per category

The two categories that we scraped from the Mercadona website for this assignment are 'Cuidado del cabello' and 'Cuidado facial y corporal'. Due to the structuring on the website, HTML code for each subcategory within the two main categories only becomes visible when changing to the URL of this specific subcategory. Therefore, the URLs for each subcategory need to be extracted to be able to read the html code. To do so, a loop per main category is created. First, one needs to create an empty list to store the URLs. Then, using the function `driver$findElement()` one navigates to the button of the first category 'Cuidado del cabello' and clicks on this button using the function `clickElement()`. Now, the category 'Cuidado del cabello' as well as the first subcategory are entered and the URL is extracted using the function `driver$getCurrentUrl()` and stored in the URL list. The category 'Cuidado del cabello' has three more subcategories left that need to be scraped. When one scrolls down to the end of the page of the subcategory, one will find a button which directs the user to the next sub category. Using a 'for loop', this button is clicked and the URL of this next subcategory is saved in the URL list. When the list includes 4 URLs, the loop terminates. This method is repeated for the second category. Two seperate loops have to be initiated as the html code of the subcategories does not allow clicking on the side navigation bar to navigate to the next category. When all URLs are collected in the URL list, the function `unlist()` is utilised to convert to an unnested list.

```{r}

#Get URLs 'Cuidado del cabello'

#Create an empty list to store the URLs 
url <- list()

#Navigate to the button 'Cuidado del cabello'
driver$findElement(value = "(//label[@class='subhead1-r' and contains(text(), 'Cuidado del cabello')])[1]")$clickElement()

#Use system sleep to avoid code running faster than the browsing
Sys.sleep(1)

#Store the first URL
url[1] <-driver$getCurrentUrl()

#Create a loop to click on the button at the end of the page to naviagte to the next subcategory and save the url
for (i in (2:4)){
 
#Find the button at the end of the page and click to navigate to the next subcategory
  driver$findElement(value = "(//button[@class = 'ui-button ui-button--big ui-button--secondary ui-button--positive category-detail__next-subcategory'])[1]")$clickElement()
  
#Use system sleep to avoid code running faster than the browsing
Sys.sleep(1)
  
#Grab the url and store the url in the url list
url[i] <-driver$getCurrentUrl()
  
  
}

#Get URLs 'Cuidado facial y corporal'
  
driver$findElement(value = "(//label[@class='subhead1-r' and contains(text(), 'Cuidado facial y corporal')])[1]")$clickElement()

Sys.sleep(1)

url[5] <-driver$getCurrentUrl()



for (i in (6:15)){
  
  
  driver$findElement(value = "(//button[@class = 'ui-button ui-button--big ui-button--secondary ui-button--positive category-detail__next-subcategory'])[1]")$clickElement()
  
  Sys.sleep(1)
  
  url[i] <-driver$getCurrentUrl()
  
}

#Unlist the URL variable
url <-unlist(url)


```

### Scraping and cleaning data

In the following chunk, the html code for each subcategory is collected, the needed data is extracted, cleaned and consequently added to a data frame. First, the function navigates to one of the URLs in the URL list. A system sleep is ultilised to avoid the code running faster than the browsing which would cause errors. Then, the html code is collected using the function `driver$getPageSource()` and read using the function `read_html()`. At this point, the html code is stored in the `cat_html` variable and can be navigated using functions from the `xml2` package. Hereafter, the data of the products is stored in the variable `cat_info` by first finding the correct tag which stores the data with the function `xml_find_all()`, and consequently converting the tag to text using the function `xml_text()`. This method is repeated to collect the names of the subcategories. The XML text strings containing the data of the products is cleaned and separated into smaller strings. First the strings are separated by inserting `a /` in the places where the string needs to be split using the `str_replace_all()` function and consequently splitting the string according to the "/" sign. The strings are split into name, quantity, quantity unit and price. Then, these sub-strings are added to a data frame together with the subcategory strings. Finally, the function `map_dfr()` is used to loop all URLs in the URL list over the function `cat_grabber` resulting in a data frame containing data on all the products of the categories 'Cuidado del cabello' and 'Cuidado facial y corporal' of the supermarket chain Mercadona.

```{r}

#Create function
cat_grabber <- function(url){
  
#Navigate to one of the URLs stored in the variable URL
driver$navigate(url)
  
#Use system sleep to avoid code running faster than the browsing
Sys.sleep(1)

#Get the page source code and read the html
cat_html <-driver$getPageSource()[[1]] |>
  read_html()

#Collect data on products
cat_info <- cat_html|> 
    xml_find_all("//*[@id='root']//button/div[2]") |>
    xml_text()

#Collect the sub category names
subcat_name <- cat_html |> 
   xml_find_all("//h1[@class='category-detail__title title1-b']") |>
   xml_text()

#Clean and separate data using regex
cat_clean<-cat_info|> 
#Replace all €, /, . or ! signs with an empty space
  str_replace_all("\\€ |/|\\.|!", "") |> 
#Replace all € signs followed by 1 or more digits, followed by a comma and again   by one or more digits with an empty space
  str_replace_all("\\€\\d+,\\d+", "") |>
#Replace ml with /ml/ when looking backwards finding first an empty space and then a digit
  str_replace_all("(?<=\\d\\s)ml", "/ml/") |> 
#Replace ud with /ud/ when looking backwards finding first an empty space  followed by a digit
  str_replace_all("(?<=\\d\\s)ud", "/ud/") |> 
#Replace ud with /ud/ when looking backwards finding first 0,1 or 2 empty spaces followed by a digit
  str_replace_all("(?<=\\d\\s{0,2})ud", "/ud/") |> 
#Replace L with /L/ when looking backwards finding first an empty space followed by a digit
  str_replace_all("(?<=\\d\\s)L", "/L/") |> 
#Replace 'tarro' with an empty space when looking backwards finding first an empty space followed by a digit
  str_replace_all("(?<=\\d\\s)tarro", "") |> 
#Replace g followed by an empty space with /g/ when looking backwards finding first an empty space followed by a digit
  str_replace_all("(?<=\\d\\s)g\\s", "/g/") |> 
#Replace g with /g/ when looking backwards finding first an empty space followed by a digit
  str_replace_all("(?<=\\d\\s)g", "/g/") |> 
#Replace 'sobres' with /sobres/ when looking backwards finding first an empty space followed by a digit
  str_replace_all("(?<=\\d\\s)sobres", "/sobres/") |> 
#Replace 'bandas' with /bandas/ when looking backwards finding first an empty space followed by a digit
  str_replace_all("(?<=\\d\\s)bandas", "/bandas/") |> 
#Replace '1' with / when looking backwards finding first an empty space followed by the word DovePaquete
  str_replace_all("(?<=sensibleCaja\\s)1", "/") |>
#Replace '4' with / when looking backwards finding first an empty space followed by the word DovePaquete
  str_replace_all("(?<=DovePaquete\\s)4", "/") |> 
#Replace ud. with an empty space when looking foreward finding 0 or more empty spaces followed by ()
  str_replace_all("ud.(?=\\s*\\()", "") |> 
#Replace an empty space with an / when looking foreward finding 1 or more digits followed by 0 or more empty spaces and a / 
  str_replace_all("\\s(?=\\d+\\s*/)", "/") |> 
#Replace a lower case letter followed by a digit with /
  str_replace_all("(?<=[[:lower:]])(?=[[:digit:]])", "/") |> 
#Replace a literal ( or a literal ) with an empty space
  str_replace_all("\\(|\\)", "") |> 
#Replace all literal . with an empty space
  str_replace_all("\\.", "")|> 
#Split the strings by /
  strsplit("/")


#Only keep the variables with 5 or less strings
cat_clean<- cat_clean[lengths(cat_clean) == 5]

#Create a dataframe
data.frame(
  name = sapply(cat_clean, `[`, 1),
  quantity = sapply(cat_clean, `[`, 2),
  quantity_unit = sapply(cat_clean, `[`, 3),
  price = sapply(cat_clean, `[`, 4),
  ud =  sapply(cat_clean, `[`, 5),
  subcat =  sapply(subcat_name, `[`, 1),
  stringsAsFactors = FALSE
)


}

cat_grabber(url)

#Loop thhe function cat_grabber over all URLs
final <- map_dfr(url, cat_grabber) 

```

#### Scrape and add main categories to data frame

To scrape and add the main categories to the data frame, the function `driver$navigate()` is used to navigate to first URL in the list which is the home page including all main categories. Then, the html code is collected and read using the functions `driver$getPageSource()` and `read_html()`. The function `xml_find_all()` is used to find the correct tag followed by the use of the `xml_text()` function in order to convert the tag into text which is stored in the variable `cat`. The category 'Cuidado del cabello' and 'Cuidado facial y corporal' are stored in the 14th and 15th position of the list respectively. Consequently, the categories are added to the data frame by matching to their subcategories.

```{r}

#Navigate to the first url
driver$navigate(url[1])
  
Sys.sleep(1)

#Grab the html code and read the html to make it accessible to functions from the 'XML2' package
cat_html <-driver$getPageSource()[[1]] |>
  read_html() 

#Collect the category names 
cat <- cat_html |> 
   xml_find_all("//label[@class='subhead1-r']") |>
   xml_text()

#Add the category names to the data frame
final <- final |> 
  mutate(cat_name = ifelse((subcat=="Acondicionador y mascarilla"|
                              subcat== "Champú"|
                              subcat== "Coloración cabello"|
                              subcat== "Fijación cabello" ),cat[14], cat[15]))

```

```{r}
#Deslect column ud bacause this column does not contain variation
final <- final |> 
  dplyr::select(-ud)
```

### Extracting brand names

In the chunk below, the brand names are extracted. The brand names are included into the name of the product without a clear or reoccurring structure. Therefore, no regex could be applied to extract these brand names. For this reason, the different brand names in the data are identified by hand and collected into a vector. Then, this vector is collapsed into a string called `brands_or`, separating the brand names by an "\|" sign. This string is used to extract the brand names from the product names using the function `str_extract_all()` and these extractions are added to a new column called "brand".

```{r}

brands <- c("Deliplus", "Elvive", "Pantene", "O'lysee", 
            "H&S", "Ultrex", "Garnier", "L'Oréal", 
            "Schwarzkopf", "Nelly", "Giorgi", "Elnett", 
            "Fructis", "Syoss", "Gillette", 
            "Nivea", "Axe", "Atlantia", "Bosque Verde", 
            "Montagne Jeunesse", "Viseger Pharma", 
            "My Moment", "Khanya", "Veet", "Wilkinson", 
            "Sanex", "Byly", "Tulipán Negro", "Dove", 
            "Deonat", "Rexona", "Heno de Pravia", "960", 
            "La Toja", "Magno", "Lactovit", "Colgate", 
            "Oral-B", "Sensodyne", "Signal", "Parodontax", 
            "Benfix", "Listerine", "Polident", "evax", 
            "Ausonia", "Carefree", "Tampax", "Tena",
            "Sense", "Classic fresh", "Rose Nude", 
            "Elección", "Prêt à Porter", "Como Tú", 
            "Como Tú", "Psicodelic", "Complicity", "Vuela", 
            "Adidas", "Soplo", "Capítulo Floral", "My soul", 
            "Blue Shine", "Verissime", "Flor de Mayo", 
            "Monogotas", "Capítulo", "Extrait", 
            "Mr. Wonderful", "Uahuu", "TokiDoki", "Ikiru",
            "Chupachups", "Rose Nude", "Rouge seduction",
            "Snoopy", "Muy mío", "Impacto", "Afán", 
            "Springfield", "Gesto", "Sesgo", "Brummel", 
            "Antonio Banderas", "Misty Wood", "Capítulo Marino", "Ego", 
            "My Soul", "Jacq's", "My Soul", "Selk",
            " Crossmen", "Gesto", "Disney", "Marvel", 
            "Naruto", "Peppa Pig", "Sonic de Hedgehog", "Colour up!", 
            "HoneyBotella")


brands_or <- paste(brands, collapse = "|")

final <- final %>% 
  mutate(brand = str_extract(name, regex(brands_or, ignore_case = TRUE)))
```

### Standardizing prices

As the prices of the products are in different quantities which are measured in different units, the prices of the products need to be standardized for them to be comparable. Hence, the price of liquid products are converted to the price of this product per 100 ml, the prices of products measured in grams are converted to the price per 100 grams, and the price of products measured in units are converted to the price of 1 unit. The latter is done using the function `case_when()` and applying the correct converting formula to the price, based on the detected measurement unit using the function `str_detect()`.

```{r}
units <- c("L", "ml", "ud", "sobres", "bandas", "g")

mercadona <- final |> 
  filter(quantity_unit %in% units) |> 
  filter(str_detect(price, "[0-9]")) |> 
  mutate(price = str_replace_all(price, ",", ".")) |> 
  mutate(quantity = as.numeric(quantity),
         price = as.numeric(price)) |> 
  mutate(avg_price = case_when(
    str_detect(quantity_unit, "g|ml") ~ (price/quantity)*100,
    str_detect(quantity_unit, "L") ~ (price/quantity)/100,
    str_detect(quantity_unit, "ud") ~ price /quantity
    )) |> 
   mutate(avg_price = round(avg_price, 2))

```

### Assigning marketed gender to product

In the following chunk, the targeted gender of the product is extracted and added to a new column in the data frame. First, different words that indicate gender are added to a vector called `gender` which is then collapsed into a string separating the words by an "\|" sign. As both the name of the product as well as the subcategory name can contain information on the gender, these two columns are temporarily combined into the variable `combine`. Then, the function `str_extract()` is used to extract the gender names from the `combined` variable and the names are stored in the variable `gender_name`. When no gender is detected, the products is assigned "NA" which are then renamed as "non-male". Hereafter, two separate vectors including male and female words are created. These vectors are used to assign "Male", "Female" or "Non-male" to the products through applying the function `case_when()` and is stored in the variable `gender`. Then, this process is repeated again but this time only assigning "male" or "non-male" to products.

```{r}
#Vector of words indicating gender
gender <-c("Men", "Women", "Man", "Woman", "Hombre", "Mujer", "Hombres", "Mujeres", "Him", "Her", "Niña", "Niñas", "Homme", "Femme", "Male", "Female", "Males", "Females", "Venus") 

#Collapsing the gender vector to a string 
gender_or <- paste(gender, collapse = "|")

mercadona <-mercadona |> 
  mutate(combined =  paste(mercadona$name, mercadona$subcat, sep = " ")) |> 
  mutate(gender_name =  str_extract(combined, regex(paste0("\\b(", gender_or, ")\\b"), ignore_case = TRUE)) ) |> 
  select(-combined)

# Convert NA to 'Non-Male'
mercadona$gender_name[is.na(mercadona$gender_name)] <- "Non-Male"


#Create Male and Female vectors
male <- c("Men", "Man", "Hombre", "Hombres", "Him", "Homme", "Male",  "Males") 

male <- c(male, tolower(male))

female <- c("Women", "Woman", "Mujer", "Mujeres", "Her", "Niña", "Niñas", "Femme", "Female", "Females", "Venus") 

female <- c(female, tolower(female))

#Assign gender to products (separate column for female)
mercadona$gender <- case_when(
  mercadona$gender_name %in% male | mercadona$subcat %in% male ~ "Male",
  mercadona$gender_name %in% female|mercadona$subcat %in% female ~ "Female",
  mercadona$gender_name == "Non-Male"~ "Non-Male")

#Assign male or non-male to products
mercadona$gender_2 <- case_when(
  mercadona$gender == "Male" ~ "Male",
  mercadona$gender == "Female" ~ "Non-Male",
  mercadona$gender == "Non-Male"~ "Non-Male")

remDr$server$stop()
```

## Clarel

For Clarel website, there is a lot of content hidden through Javascript so we will use Selenium to scrape all the interested content. The setup on this computer was initially troublesome as we wanted to use Chrome as browser. There were a few fix suggestions and the only one that worked was to delete the "LISCENSE.chromever" file for the corresponding. However, there was no clear explanation to this fix and the potential issues with deleting the file so we will use Firefox browser for selenium instead.

### Data Collection

```{r}
#remove driver from last session
rm(driver)
rm(remDr)
```

For this section we will initialize the RSelenium driver again, we will remove the previous "driver" and "remDr" objects since it sometimes causes some errors when running another session of Selenium driver.

```{r}
driver <- rsDriver(browser = "firefox",
                   chromever = NULL,
                   verbose = F)

remDr <- driver[["client"]]
```

We first initialize the Selenium server again and create a remote driver session. We're saving the client object to a variable for quicker access later on.

#### Main Webpage

```{r}
clarel_url <- "https://www.clarel.es/es/"

remDr$navigate(clarel_url)

Sys.sleep(2)

#click on a random element to activate the page
remDr$findElement(using = "xpath", "//div[@class ='header-top-navigation']")$clickElement()

Sys.sleep(2)

#Reject cookies
remDr$findElement(using = "xpath", "//button[contains(@class, 'info_cookie-consent-reject-button')]")$clickElement()
```

Once we navigate to the home page of Clarel, there is a pop up for cookies so we will need to either accept or reject the cookies. We leave the system to pause for 2 seconds after navigating to the home page so the browser has sufficient time to load everything. Next, it seems that the page only start to load after there is some mouse movement on the page. Therefore, we send a click to a random element on the page to activate the rest of the page. After this, the cookies pop up should appear and then we send a click to the rejection button. If reject cookies line code runs into error, most likely it is because the page has not fully loaded and the pop up has not appeared yet therefore the button is not found. It is necessary to run again the reject cookies code. If it still runs into error, it is likely that the elements in the web page have changed their name.

#### Scrape Hombre Category

We will start by scraping one category before streamline the scraping process for multiple categories. The structure of the pages of all categories are quite similar so we should not run into many troubles later on if we can scrape one category properly. In this project, we chose to start with "Hombre" category.

```{r}
#helper function to get all subcategories of main category input
get_subcat2_url <- function(category){
  #get all the nodes containing category keyword
  all_nodes <- remDr$getPageSource()[[1]] %>% 
    read_html() %>% 
    xml_find_all(glue("//a[contains(@href,'/{category}/')]")) %>% 
    xml_attr("href") %>% 
    .[str_detect(.,"https",negate = TRUE)] %>% 
    unique(.)
  
  #get subcategories and sub-subcateogry(product type) 
  sub_cat <- all_nodes[str_detect(all_nodes, glue("es/{category}/\\w+(-\\w+)?$"))]
  product_type <- all_nodes[str_detect(all_nodes, glue("{category}/\\w+(-\\w+)?/\\w+"))]
  
  #identify subcategories with no product type to include in list to scrape
  no_product_type <- c()
  for (i in sub_cat) {
    if(!any(str_detect(product_type, i))) {
      no_product_type <- c(no_product_type,i)
    }
  }
  
  #all urls to subcategories and sub-subcategories of the main categories
  all_urls <- c(no_product_type, product_type) %>% 
    paste0("https://www.clarel.es",.)
  
  return(all_urls)
}

#test run
sub_cat_2_url <- get_subcat2_url("hombre")
sub_cat_2_url
```

In each main category of products on Clarel, there are also sub-categories and in each of the sub-category sometimes there are sub-section (they will be referred as product type in this document) with the details the product type as well. We would like to get all of this information so later we have more resources to work with for the analysis in case that we need it.

To do this, first a helper function is created to grab all the URLs to the sub-categories and product types. Another option would have been to navigate to each sub-category and grab the product types but it is more time consuming as we would need to go to multiple product type pages of multiple sub-category pages and the loading time would amass quickly. Therefore, we tried to identify all the URLs from the home page but the trade-off is some cleaning in the process.

The logic of this function is of below:

-   The input (parameter) is the main category that we are interested in.

-   The function then finds all the anchor links containing the category, extracts those links, cleans irrelevant links and duplicated links, then saves them into a variable.

-   The function continues to extract sub-category links and product type links. The product types are subsection of the sub-category, therefore, we need to exclude them from the URL list to avoid scraping duplicated items.

-   The cleaning of these links are done by detecting if the URL list of product type contains the sub-category. (For example, "afeitado" sub-category URL contains "es/hombre/afeitado". A product type of this sub-category is "despues afeitado" and its URL would be "es/hombre/afeitado/despeues-afeitado". The URL of "despues afeitado" contains URL of afeitado so we can base on that and exclude "afeitado" from the list)

-   The function returns a vector of product type URLs and sub-categories with no product types URLs

Using this function, we can obtain all the necessary URLs to scrape all the products of the main category divided by sub-categories and product types. Now we will move on to scrape the products of each URL.

```{r}
#Load more items helper function
load_all_items <- function() {
  Sys.sleep(2)
  tryCatch(
    {
      suppressMessages({
      load_more_button <-remDr$findElement(using = "xpath", 
                                          "//button[contains(@class, 'load-more-items-button')]")
      while(load_more_button$isElementDisplayed()[[1]]) {
      load_more_button$clickElement()
      Sys.sleep(2)
      load_more_button <-remDr$findElement(using = "xpath", 
                                           "//button[contains(@class, 'load-more-items-button')]")
      }
      })
    },
    error = function(e){})
}

#test run
# load_all_items()
```

Navigating to the URL of the sub-categories and product types gives us a list of products. However, the pages have a lot of products and not all are shown on the page. These products are hidden after the "Ver más productos" ("See more products") and we need to repeatedly click on the button until all the products are shown.

Above, we created a function to click the button until the button is gone, meaning that all products have been loaded. There are pauses between each click to wait for the products to load. Since we do not know how many times we have to click the button, we use a `while` loop to click the button until there is no more button to click. When there is no more button, we would get an error if we tried to find the button so we use a `tryCatch()` function to catch and ignore this error.

With this helper function to load all the products, we now can scale and go to all URL, load all the products, and scrape them.

```{r}
#Get all product info helper function
get_product_info <- function(url) {
  remDr$navigate(url)
  
  load_all_items()
  
  paths <- read_html(remDr$getPageSource()[[1]]) %>% 
  xml_find_all("//div[contains(@class, 'box_product-info')]")
  
  get_info <- function(path) {
  brand <- path %>% 
    xml_find_all("div[contains(@class, 'product-featuredbrands')]") %>%
    xml_text()
  
  product_name <- path %>% 
    xml_find_all("a") %>% 
    xml_text()
  
  price <- path %>% 
    xml_find_all("div[contains(@class, 'product-price')]/span[contains(@class,'final-price')]") %>% 
    xml_text()
  
  data.frame(
    brand = brand,
    product_name = product_name,
    price = price
  )
  }
  
  #Get categories & subcategories to add to the dataframe
  cat <- remDr$getPageSource()[[1]] %>% 
    read_html() %>% 
    xml_find_all("//span[@class='subcategory']") %>% 
    xml_text() %>% 
    paste(collapse = "-")
  
  df <- map_dfr(paths, get_info) %>% mutate(full_cat = cat)

  
  return(df)
}

#test run
hombre_products <- map_dfr(sub_cat_2_url, get_product_info)

hombre_products
```

Now, we need to get the information of the products. We will similarly create a helper function to streamline the process. The function we created take a URL for input, navigates to that URL, loads all the products using the function created previously, then it gets all the paths (nodes) of the `div` tags containing information about the products. After this, we nested a function to grab the product information from the `div` tags, which at the end returns the data frame of the product information, including brand name, product name, and price. Since categories, sub-categories, and product types are in other elements of the page, we grabbed them separately and append to the data frame to finally create a data frame with brand, product name, price, and full category columns consisting of main category, sub-category, and product type (if any) joined together by "-" (e.g., "Hombre-Afeitado-Después Afeitado").

#### Scrape Multiple Categories

```{r}
#all main categories to be scraped
imp_cat <- c("hombre", "higiene", "cabello", "perfumes")

#helper function to scrape data on large scale
scrape_all <- function(category) {
  remDr$navigate(clarel_url)
  
  subcat2 <- get_subcat2_url(category)
  
  df <- map_dfr(subcat2, get_product_info) 
  
  return(df)
}

all_products_clarel <- map_dfr(imp_cat ,scrape_all)

#write into csv to avoid scraping every time
write_csv(all_products_clarel, "datasets/clarel.csv")

#close server
driver$server$stop()
```

With the helper functions created before, we have all the tools needed to scrape products from Clarel web page on a large scale (multiple categories). We create a vector with all the interested categories and a function to automate the scraping. This function navigates to the home page of Clarel, then extracts all URLs of sub-categories and product types of the main category input, and finally gets all the product information using the function from the last section to produce a final data frame. We use `map_dfr` to apply the function on the vector of interested categories and create a comprehensive data frame.

At the time of writing this project, it took around 8 minutes to scrape the 4 categories hombre, higiene, cabello, and perfumes. We saved the scraped data into a csv file so for the analysis we would not have to repeat the scrape every time. Furthermore, if there are any changes to the web page and the functions no longer work, the analysis is still reproducible with the csv file.

### Data Cleaning

```{r}
#loading the data frame from the file created after scraping
all_products_clarel <- read_csv("datasets/clarel.csv")
```

```{r}
#helper function to id gender & kid of products
gender_id <- function(str){
  male <- c("men", "man", "hombre", "hombres", "him", "homme", "male",  "males", "masculino") 

  female <- c("women", "woman", "mujer", "mujeres", "her", "femme", "female", "females", "venus", "femenina") 

  kids <- c("kid", "kids", "niños", "niño", "niñas", "niña", "infantil", "infantiles")
  
  str <- tolower(str)
  
  if(str_detect(str, paste0("\\b(", kids, ")\\b", collapse = "|"))) {
    return("Kid")
  } else if(str_detect(str, paste0("\\b(", female, ")\\b", collapse = "|"))) {
    return("Female")
  } else if(str_detect(str, paste0("\\b(", male, ")\\b", collapse = "|"))) {
    return("Male")
  } else {return(NA)}
  
}
```

It is extremely tricky to identify which products are aimed at men or women (especially women) because most products do not include this information. They are more easily identified through the pictures and packaging choice (such as pink color and with a woman figure for women products) but since we work with only text we are very limited to the ability to identify to which gender the product is geared toward. Some products are in "Hombre" category so they are easily classified for men but the other categories do not clearly indicate gender. We will try to detect this information using keywords in the product names and sub-categories.

Above, we created some lists of words that could indicate whether the products are for men or women or kids. We also try to identify kids products because later on we will discard them since it is not the scope of this project. We then put those lists into a function that takes a string as input and detects whether in the string there is any word from the list, then categorizes the string accordingly.

```{r}
cleaned_clarel <- all_products_clarel %>% 
  as_tibble() %>% 
  #Remove duplicated products
  distinct(product_name, .keep_all = TRUE) %>% 
  #Mutate to later split into cateogries and subcategories
  mutate(
    full_cat = str_replace(full_cat, "-", "/")
  ) %>% 
  #Split category into sub category and product type
  separate_wider_delim(full_cat, delim = "/", names = c("category", "sub_category")) %>% 
  #Extract quantity with unit
  mutate(qty = str_extract(tolower(product_name), "\\d+ ?ml|\\d+ ?g|\\d+ ?ud(s)?|\\d+(,\\d+)? ?l") ,.after = product_name) %>% 
  #NA rows in quantity means product is sold in 1 unit
  mutate(qty = replace_na(qty, "1")) %>% 
  #Extract unit of quantity
  mutate(
    qty_unit = ifelse(qty == 1, "ud", str_extract(qty, "ml|l|ud|g")),
    price = parse_number(str_replace(price, "€", ""), locale = locale(decimal_mark = ",")),
    qty = parse_number(qty,locale = locale(decimal_mark = ","))) %>% 
  #Calculate average price
  mutate(
    avg_price = case_when(
      str_detect(qty_unit, "ml|g") ~ price * 100 / qty, #price per 100ml/g
      qty_unit == "ud" ~ price / qty, #price per unit
      qty_unit == "l" ~ price *0.1 / qty, #price per 100ml for Litters
      TRUE ~ price 
    )
  ) %>% 
  #Round average price and identify targeted gender of product
  mutate(avg_price = round(avg_price, 2),
         gender = case_when(
           (category == "Hombre" | str_detect(sub_category, "Hombre")) ~ "Male",
           TRUE ~ mapply(gender_id, paste(product_name, sub_category))
           )
         ) %>% 
  #Replace non gender specific product with non-male
  mutate(gender = replace_na(gender, "Non-Male"),
         #gender_2 to compare male vs non-male targeted products
         gender_2 = ifelse(gender == "Male", "Male", "Non-Male")) %>% 
  #Remove products for kids
  filter(gender != "Kid") %>% 
  #Reorganise column names to join with other datasets
  dplyr::select(product_name, qty, qty_unit, price, sub_category, category, brand, avg_price, gender, gender_2)
```

As for most web scraping projects, the scraped data is usually messy and needs diligent cleaning so it is appropriate for analysis. The same goes for the data scraped here previously.

First we remove the duplicated products since products in some categories overlap and therefore appear multiple times in the data set. We then split the full category into main category and sub-category (which also includes product types). We first replace the first "-" of the full category collumn with another symbol so we can split into 2 columns based on that symbol.

Next, we extract the quantity from the product name. The product name contains various information from the product to brand name, quantity, and more. We extract the quantity using Regex and look for numbers followed by quantity symbol (ml, L, g, u/ud/uds). If the product name does not contain any of these, it is most possible that the product is sold as one unit whole. Therefore, after extracting products with specific quantities, we impute the missing rows with 1 unit.

We then extract the unit of the quantity then calculate the average price based on the unit. For milliliter (ml), gram (g), and litter (l) the average price is per 100 ml or g. For products that are sold in more than 1 unit the average price is calculated as per unit. Lastly, they are rounded at 2 decimal places.

Finally, we detect the gender for which the product aims. First, all products in category "Hombre" are named "Male" and then we use the gender identifying function from before to detect if the product name or product sub-category/product type indicates that it is for men or women or kids. Since few products are explicitly described as for women, we make another label called "Non-Male" to compare specifically male-targeted products versus non-male-targeted products. The gender column include 4 different labels (Male, Female, Kid, and Non-Male). The gender_2 column consists of only 2 (Male and Non-Male). These are made for the purpose of analysis.

## Data Joining

```{r}
#Modify mercadona dataframe to join
mercadona_cleaned <- mercadona |> 
  select(-gender_name) |> 
  mutate(store = "Mercadona")

cleaned_clarel <- cleaned_clarel |> 
  mutate(store = "Clarel")

#Match column names
colnames(cleaned_clarel) <- colnames(mercadona_cleaned)

#helper function
match_cat <- function(str) {
  str <- tolower(str)
  
  cat <- case_when(
    str_detect(str, "afeitado") ~ "Afeitado",
    str_detect(str, "champú") ~ "Champú",
    str_detect(str, "acondicionador|mascarilla") ~ "Acondicionador y Mascarilla",
    str_detect(str, "coloración|tinte") ~ "Coloración",
    str_detect(str, "fija") ~ "Fijación cabello",
    str_detect(str, "corporal") ~ "Cuidado corporal",
    str_detect(str, "facial") ~ "Cuidado facial",
    str_detect(str, "depilación") ~ "Depilación",
    str_detect(str, "desodorante") ~ "Desodorante",
    str_detect(str, "gel") ~ "Gel y Jabón",
    str_detect(str, "higiene bucal") ~ "Higiene bucal",
    str_detect(str, "higiene íntima") ~ "Higiene íntima",
    str_detect(str, "manicura|pedicura") ~ "Manicura y Pedicura",
    str_detect(str, "perfume") ~ "Perfume",
    str_detect(str, "solar") ~ "Protector solar y aftersun"
  )
  
  return(cat)
}

#Join 2 dataset together

big_df <- bind_rows(mercadona_cleaned, cleaned_clarel) %>% 
  #sub-category matching
  mutate(match_subcat = match_cat(subcat), .after = subcat) %>% 
  #match by product name if sub-cat doesn't match
  mutate(match_subcat = ifelse(is.na(match_subcat), match_cat(name), match_subcat)) %>% 
  #other subcats that have no match for either sub-cat and product name
  mutate(match_subcat = replace_na(match_subcat, "Other"))

```

```{r}
big_df <- big_df |> 
  mutate(type_brand = ifelse((brand == "Deliplus"|brand == "NESK"|brand == "BONTE") ,"Housebrand", "Brand"))
```

To join the 2 data frames of Mercadona products and Clarel's, their columns need to have the same names and positions to bind with `bind_rows` function. Since the categories and sub-categories of the 2 websites are named differently. We would need to match them so later analysis can be done properly. A function to match strings into categories is created to facilitate this process. The matched category column is created by applying this function to the sub-category column and then again on the product name column in order to identify over as many items as possible. For the categories that could not find a match, we put them into "Other".

Next, we also identified home brands of both Mercadona and Clarel so we can later elaborate the analysis on home brands versus non home brands.

### Saving the data

The html code of the websites might change which will cause the scraping code to stop functioning, the full data frame is stored in a csv file names "full_data.csv". Then, the csv file is loaded back into R to continue with the analysis.

```{r}
write_csv(big_df, "datasets/full_data.csv")

full_data <- read_csv("datasets/full_data.csv")

```

## Data balancing

Given that the data set is rather unbalanced with regards to the number of "male" and "non-male" products, the data set is balanced based on the `gender_2` variable. The balancing method applied both undersamples the majority class and oversamples the minority class to generate a data set in which approximately half of the cases are from the original majority class and half of the cases of the original minority class. This balancing is necessary for the application of t-test to compare the price means of the "male" and "non-male" category.

```{r}
# Plot the distribution of 'gender_2' 
full_data |> 
  ggplot(aes(x=gender_2)) +
  geom_bar()

#Remove missing values
full_data <-full_data |> 
  drop_na()

#Create the cross table and the proportion table
table(full_data$gender_2)
prop.table(table(full_data$gender_2))

#Perform data balancing
df_balanced <- ovun.sample(gender_2~., data=full_data, method = "both",
                    p = 0.5,
                    seed = 123,
                    N = 3600)$data 
table(df_balanced$gender_2)

#Check the balanced data set
df_balanced |> 
  ggplot(aes(x=gender_2)) +
  geom_bar()


```

## Removing outliers

The code below removes the outliers in the data set grouped by the subcategory and the gender (male, non-male). The first and third quartiles of the `avg_price` variable within each group defined by the previous `group_by` operation are computed. Then, the interquartile range (IQR) of the `avg_price` variable within each group is computed. The lower and upper bounds for outliers are computed based on the IQR method. Outliers are defined as values that fall below Lower or above Upper. Only the rows where the avg_price falls within the calculated bounds is maintained in the data set by applying the function `subset()`. Finally, the data set is ungrouped.

```{r}
# Group the data frame by 'match_subcat' and 'gender_2'
df_balanced <- df_balanced |> 
  group_by(match_subcat, gender_2)
 
# Calculate quartiles and IQR for 'avg_price' within each group
quartiles <- quantile(df_balanced$avg_price, probs=c(.25, .75), na.rm = FALSE)
IQR <- IQR(df_balanced$avg_price)
 
# Calculate lower and upper bounds for outliers
Lower <- quartiles[1] - 1.5*IQR
Upper <- quartiles[2] + 1.5*IQR 
 
# Remove outliers based on the calculated bounds
df_balanced <- subset(df_balanced, df_balanced$avg_price > Lower & df_balanced$avg_price < Upper)

# Ungroup data
df_balanced <- df_balanced |> 
  ungroup()

```

## Mean comparisons

In this section, the prices between male and non-male products are compared with each category and subcategory.

### Categories

To start, a function is created within which first a data set is created named `cat_d` which is the `df_balanced` but filtered by a specific combination of the category name and the quantity unit. Then, the standardized price ("avg_price") is filtered by "male" and "non-male" and stored in the variables `prices_male` and `prices_non-male` respectively. Hereafter, an empty variable named `t_test_result` is created to later store the results from the t-test analyses and the t-test function is inserted within a `tryCatch()` function as not all t-tests will be valid and generate results. When the t-test failed, the results are assigned NA and the function continues. The t-test function tests whether the prices of the male products are significantly lower then the prices of non-male products. The function `tidy()` is used to convert the output of the t-test into a tibble.

Once the function is correctly specified, a loop function is created to apply the function to all combinations of category and quantity unit. The unique category names are saved into a data frame named "cat_loop" using the function `dinstinct()`. Then, the column "cat_name" from the "cat_loop" data frame is converted into a nested list by applying the `as.list()` function and is then unnested through the function `unlist()`. As each category will be tested per quantity unit, a new list names "cat_f" is created in which the category names are duplicated using the `rep()` function. A vector called "quan_f" is created in which the two main quantity units "ml" and "ud" are alternating repeated both 6 times. An empty list named "x" is created to store the results of the t-test. Hereafter, a loop is created which applies the `t-test-fun` to the items in the "cat_f" and "quan_f" vectors. All tibbles containing the results of the different t-test are combined into one data frame named "result_cat" using the function `do.call()` in combination with `rbind()`. The corresponding categories and units are added to the "result_cat" data frame to enhance interpretability. Then, this data frame is cleaned by properly renaming the columns and organising the columns in a more logical order.

```{r}

cat_f <- c("Higiene")
quan_f <- c("ml")

#Filter data based on the category name and the quanity unit
t_test_fun <- function(cat_f, quan_f) {
  cat_d <- df_balanced |> 
    filter(cat_name == cat_f & quantity_unit == quan_f)
 
  # Create a varianle contaning the prices for male and non-male prices seperately 
  prices_male <- cat_d$avg_price[cat_d$gender_2 == "Male"]
  prices_non_male <- cat_d$avg_price[cat_d$gender_2 == "Non-Male"]
  
  #Create an empty vaiable to store the results of the t-tests
  t_test_result <- NULL
 
  #Use tryCatch to assure when the t-test failed, the results are assigned NA and    the function continues.
  tryCatch({
    t_test_result <- tidy(t.test(prices_male, prices_non_male))
  }, error = function(e) {NA
    
  })
}

#Test the function
t_test_fun(cat_f, quan_f)

# Extract the disticnt category bames
cat_loop<- df_balanced |> 
  distinct(cat_name) 

#Create a list of the category names
cat_loop <- as.list(cat_loop$cat_name)
#Unlist 
cat_loop <- unlist(cat_loop)
#replicate the categories twice
cat_f <- rep(cat_loop, each = 2) 

#Create a vector with the quanitity units
quan_f <- c("ml", "ud")
# Repeat the quanity units six times to match the number of categories
quan_f <- rep(quan_f, times = 6)

#Create an empty list to store the results from the t-test function
x <- list()

#Run a for-loop to aply the t-test function to all categories
for (i in seq_along(cat_f)) {
  result <- t_test_fun(cat_f[i], quan_f[i])
  x[[i]] <- result
}

# Combining the results into a data frame
result_cat <- do.call(rbind, x)
#Adding the category names
result_cat$category <- cat_f
#Adding the quanitity units
result_cat$quantity_unit <- quan_f

#Clean the results
result<-result_cat |> 
  select(category, quantity_unit, everything()) |> 
  rename(diff_male_non_male = estimate, 
         male = estimate1, 
         non_male = estimate2,
         t_statistic = statistic,
         df = parameter) |> 
  mutate(p.value = round(p.value, 3)) |>  
  drop_na() 

#Create a df with only significant results
resul_sig <- result |> 
  filter(p.value <=0.05)
  



```

### Sub-categories

The method for obtaining the t-test results is repeated with minor adjustments to obtain the t-test results for the sub-categories. The data is filtered based on the subcategory. Also, the number of repetitions of the quantity units are changed according to the number of subcategories.

```{r}
cat_f <- c("Champú")
quan_f <- c("ml")


t_test_fun <- function(cat_f, quan_f) {
  cat_d <- df_balanced |> 
    filter(match_subcat == cat_f & quantity_unit == quan_f)
  
  prices_male <- cat_d$avg_price[cat_d$gender_2 == "Male"]
  prices_non_male <- cat_d$avg_price[cat_d$gender_2 == "Non-Male"]
  
  t_test_result <- NULL
  
  tryCatch({
    t_test_result <- tidy(t.test(prices_male, prices_non_male))
  }, error = function(e) {NA
    
  })
}

t_test_fun(cat_f, quan_f)

cat_loop<- df_balanced |> 
  distinct(match_subcat)

cat_loop <- as.list(cat_loop$match_subcat)
cat_loop <- unlist(cat_loop)
cat_f <- rep(cat_loop, each = 2) 


quan_f <- c("ml", "ud")
quan_f <- rep(quan_f, times = 16)


x <- list()

for (i in seq_along(cat_f)) {
  result <- t_test_fun(cat_f[i], quan_f[i])
  x[[i]] <- result
}

# Combining the results into a data frame
result_df <- do.call(rbind, x)
result_df$match_subcat <- cat_f
result_df$quantity_unit <- quan_f




result_sub<-result_df |> 
  select(match_subcat, quantity_unit, everything()) |> 
   rename(diff_male_non_male = estimate, 
         male = estimate1, 
         non_male = estimate2,
         t_statistic = statistic,
         df = parameter) |> 
  mutate(p.value = round(p.value, 3)) |> 
  drop_na() 

result_sub_sig <- result_sub |> 
  filter(p.value <=0.05)
```

As the prices seem to differ considerably between branded and house brand products as well as the frequency of these products in the data set, the following t-test will be run separating the branded and house brand products.

```{r}
avg_prices <- df_balanced %>%
  group_by(gender_2, type_brand) %>%
  summarise(avg_price = mean(avg_price))

# Plot
ggplot(aes(x = gender_2, fill = type_brand), data = df_balanced) +
  geom_bar(position = "dodge") +
  geom_text(data = avg_prices, aes(x = gender_2, y = avg_price, label = round(avg_price, 2)), 
            position = position_dodge(width = 0.9), vjust = -0.5) +
  scale_fill_manual(values = c("blue", "pink")) +
  labs(fill = "Type Brand") +
  ylab("Frequency product")+
  xlab("Gender Product")
```

The following chunk functions similar to the chunk above. However, the data set is filtered to create a data set only including the house brands.

```{r}

df_house_brands<- df_balanced |> 
  filter(type_brand == "Housebrand")


cat_f <- c("Champú")
quan_f <- c("ml")


t_test_fun <- function(cat_f, quan_f) {
  cat_d <- df_house_brands |> 
    filter(match_subcat == cat_f & quantity_unit == quan_f)
  
  prices_male <- cat_d$avg_price[cat_d$gender_2 == "Male"]
  prices_non_male <- cat_d$avg_price[cat_d$gender_2 == "Non-Male"]
  
  t_test_result <- NULL
  
  tryCatch({
    t_test_result <- tidy(t.test(prices_male, prices_non_male))
  }, error = function(e) {NA
    
  })
}

t_test_fun(cat_f, quan_f)

cat_loop<- df_house_brands |> 
  distinct(match_subcat)

cat_loop <- as.list(cat_loop$match_subcat)
cat_loop <- unlist(cat_loop)
cat_f <- rep(cat_loop, each = 2) 


quan_f <- c("ml", "ud")
quan_f <- rep(quan_f, times = 16)


x <- list()

for (i in seq_along(cat_f)) {
  result <- t_test_fun(cat_f[i], quan_f[i])
  x[[i]] <- result
}

# Combining the results into a data frame
result_df <- do.call(rbind, x)
result_df$match_subcat <- cat_f
result_df$quantity_unit <- quan_f




result_sub_house_brands<-result_df |> 
  select(match_subcat, quantity_unit, everything()) |> 
   rename(diff_male_non_male = estimate, 
         male = estimate1, 
         non_male = estimate2,
         t_statistic = statistic,
         df = parameter) |> 
  mutate(p.value = round(p.value, 3)) |> 
  drop_na() 

resul_sig_sub_house_brands <- result_sub_house_brands |> 
  filter(p.value <=0.05)
```

A new data frame is create only including the branded products.

```{r}
df_brands<- df_balanced |> 
  filter(type_brand == "Brand")


cat_f <- c("Champú")
quan_f <- c("ml")


t_test_fun <- function(cat_f, quan_f) {
  cat_d <- df_brands |> 
    filter(match_subcat == cat_f & quantity_unit == quan_f)
  
  prices_male <- cat_d$avg_price[cat_d$gender_2 == "Male"]
  prices_non_male <- cat_d$avg_price[cat_d$gender_2 == "Non-Male"]
  
  t_test_result <- NULL
  
  tryCatch({
    t_test_result <- tidy(t.test(prices_male, prices_non_male))
  }, error = function(e) {NA
    
  })
}

t_test_fun(cat_f, quan_f)

cat_loop<- df_brands |> 
  distinct(match_subcat)

cat_loop <- as.list(cat_loop$match_subcat)
cat_loop <- unlist(cat_loop)
cat_f <- rep(cat_loop, each = 2) 


quan_f <- c("ml", "ud")
quan_f <- rep(quan_f, times = 15)


x <- list()

for (i in seq_along(cat_f)) {
  result <- t_test_fun(cat_f[i], quan_f[i])
  x[[i]] <- result
}

# Combining the results into a data frame
result_df <- do.call(rbind, x)
result_df$match_subcat <- cat_f
result_df$quantity_unit <- quan_f




result_sub_brands<-result_df |> 
  select(match_subcat, quantity_unit, everything()) |> 
   rename(diff_male_non_male = estimate, 
         male = estimate1, 
         non_male = estimate2,
         t_statistic = statistic,
         df = parameter) |> 
  mutate(p.value = round(p.value, 3)) |> 
  drop_na() 

resul_sig_sub_brands <- result_sub_brands |> 
  filter(p.value <=0.05)
```

## Discussion

When comparing the mean prices of the male and non-male marketed products, for most of the main categories, the male products seem to be higher prices. However, for hygiene products, the non-male products are cheaper. When inspecting the price differences by sub category, most male marketed products are again more expensive. Some of the subcategories have rather large differences such as a differences of 5€ for skin care products (cuidado facial). Moreover, there are large differences in prices when performing the analysis only on house brand products for the categories "Coloración (ud)", "Cuidado facial (ud)" having a significantly higher price for male products compared to non-male products and "Depilación (ml)" having a significantly lower price for male marketed products. However, one should not that significant results are only found for 3 of the 16 subcategories. When performing the analysis only on branded products, the product sub-categories with significant price differences show higher prices for the male targeted products compared to the non-male targeted products. Only products in the sub categories "Desodorante (ml)" and 'Fijación cabello (ml)' are more expensive in case of non-male targeted products. Note that again in 6 of the 16 subcategories for only one of the two measurement units a significant price difference has been found. Unfortunately, the t-test were not computed for all combinations of subcategories and measurement units due to small numbers of cases in some of these combinations.

## Conclusion

The analysis is price differences mainly showed significantly higher prices for male marketed products compared to non-male marketed products. Also, these differences are different for branded and house-branded products. Interestingly, when non-male marketed products showed higher prices, these are products mainly used only by women such as hairspray or hair removal products.

### Limitations

As the data set was highly unbalances which corrupted the t-testing, the data set has been balanced. This mainly included oversampling the male marketed products. However, oversampling causes overestimation of the category it is oversampling which might have lead to overestimation of the male marketed product prices. To overcome this possible issue, it is advised to increase the sample size in future analyses to make undersampling the majority category possible.

As mentioned in the introduction, the analysis performed above could be greatly improved when the detection of gender is done using image recognition methods rather than assigning by gender based on the name or description of the product as the latter often only contains information on gender in the case of male marketed products. However, the design of the product often clearly conveys whether the product is targeted at men or women through, for example, the use of colour. Moreover, attributes that contribute to price differences such as the quality have not been included in this analysis. It is possible that the distribution of attributes is different for male and female products which influences the mean price of these products. Furthermore, it is advisable to include a larger number of stores to avoid the impact of store specific differences.

## Bibliography

Economic Committee United States Congress (2016). Retrieved March 11, 2024, <https://www.jec.senate.gov/public/_cache/files/8a42df04-8b6d-4949-b20b-6f40a326db9e/the-pink-tax---how-gender-based-pricing-hurts-women-s-buying-power.pdf>

Guittar, S. G., Grauerholz, L., Kidder, E. N., Daye, S. D., & McLaughlin, M. (2022). Beyond the pink tax: gender-based pricing and differentiation of personal care products. *Gender Issues*, *39*(1), 1-23.
